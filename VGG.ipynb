{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edfec25d-0e1e-448e-bedf-ca091f58ea63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "# Needed for VGG16\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from sklearn.datasets import load_files   \n",
    "from glob import glob\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.saving import load_model\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21db4f-bb28-4a24-ac5b-490982659d21",
   "metadata": {},
   "source": [
    "# Loading Data (Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3260ba1-e8e9-4f2c-a43b-3c1bdff917f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./Data/X_train.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "with open('./Data/y_train.npy', 'rb') as f:\n",
    "    y_train = np.load(f)\n",
    "with open('./Data/X_test.npy', 'rb') as f:\n",
    "    X_test = np.load(f)\n",
    "with open('./Data/y_test.npy', 'rb') as f:\n",
    "    y_test = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610ffeb1-d1ac-4fbf-ab77-7a242065e83b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dimensions = (200, 200)\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b2ca0-b198-4446-8ea8-c92e714650df",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8182b315-1cfb-4e6a-8398-3fabd652a435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Necessary for ResNet Dense Layer\n",
    "y_train_eye = np.eye(num_classes)[y_train.reshape(-1)]\n",
    "y_test_eye = np.eye(num_classes)[y_test.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5354c74e-b02c-4128-985f-e751b0e96a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6711f11-f24f-4c99-8077-f86585c75bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "base_model = VGG16(weights= None, include_top=False, input_shape=(dimensions[0], dimensions[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4cc11e8-f8e8-459e-9235-db3073b92e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c74c9c1-dcaf-4cd9-8971-400e73039dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "# sgd = SGD(learning_rate=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61fcd0bd-1ae3-4547-8e92-29abf6a6324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "132/132 [==============================] - 1180s 9s/step - loss: 2.0631 - accuracy: 0.3792\n",
      "Epoch 2/25\n",
      "132/132 [==============================] - 1125s 9s/step - loss: 1.0150 - accuracy: 0.6178\n",
      "Epoch 3/25\n",
      "132/132 [==============================] - 1115s 8s/step - loss: 0.7566 - accuracy: 0.6878\n",
      "Epoch 4/25\n",
      "132/132 [==============================] - 1116s 8s/step - loss: 0.5423 - accuracy: 0.7667\n",
      "Epoch 5/25\n",
      "132/132 [==============================] - 1146s 9s/step - loss: 0.4451 - accuracy: 0.8000\n",
      "Epoch 6/25\n",
      "132/132 [==============================] - 1203s 9s/step - loss: 0.3526 - accuracy: 0.8447\n",
      "Epoch 7/25\n",
      "132/132 [==============================] - 1156s 9s/step - loss: 0.2993 - accuracy: 0.8807\n",
      "Epoch 8/25\n",
      "132/132 [==============================] - 1153s 9s/step - loss: 0.2514 - accuracy: 0.8953\n",
      "Epoch 9/25\n",
      "132/132 [==============================] - 1194s 9s/step - loss: 0.1634 - accuracy: 0.9361\n",
      "Epoch 10/25\n",
      "132/132 [==============================] - 1108s 8s/step - loss: 0.1738 - accuracy: 0.9308\n",
      "Epoch 11/25\n",
      "132/132 [==============================] - 1095s 8s/step - loss: 0.1203 - accuracy: 0.9565\n",
      "Epoch 12/25\n",
      "132/132 [==============================] - 1112s 8s/step - loss: 0.0854 - accuracy: 0.9713\n",
      "Epoch 13/25\n",
      "132/132 [==============================] - 1075s 8s/step - loss: 0.0921 - accuracy: 0.9698\n",
      "Epoch 14/25\n",
      "132/132 [==============================] - 1080s 8s/step - loss: 0.1828 - accuracy: 0.9304\n",
      "Epoch 15/25\n",
      "132/132 [==============================] - 1075s 8s/step - loss: 0.0799 - accuracy: 0.9717\n",
      "Epoch 16/25\n",
      "132/132 [==============================] - 1074s 8s/step - loss: 0.0647 - accuracy: 0.9783\n",
      "Epoch 17/25\n",
      "132/132 [==============================] - 1071s 8s/step - loss: 0.0692 - accuracy: 0.9755\n",
      "Epoch 18/25\n",
      "132/132 [==============================] - 1080s 8s/step - loss: 0.0403 - accuracy: 0.9863\n",
      "Epoch 19/25\n",
      "132/132 [==============================] - 1082s 8s/step - loss: 0.0521 - accuracy: 0.9819\n",
      "Epoch 20/25\n",
      "132/132 [==============================] - 1087s 8s/step - loss: 0.0699 - accuracy: 0.9778\n",
      "Epoch 21/25\n",
      "132/132 [==============================] - 1074s 8s/step - loss: 0.0604 - accuracy: 0.9787\n",
      "Epoch 22/25\n",
      "132/132 [==============================] - 1062s 8s/step - loss: 0.0521 - accuracy: 0.9824\n",
      "Epoch 23/25\n",
      "132/132 [==============================] - 1069s 8s/step - loss: 0.0676 - accuracy: 0.9754\n",
      "Epoch 24/25\n",
      "132/132 [==============================] - 1067s 8s/step - loss: 0.0719 - accuracy: 0.9813\n",
      "Epoch 25/25\n",
      "132/132 [==============================] - 1080s 8s/step - loss: 0.0240 - accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4857f4bb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_ros, y_train_ros, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d545a93e-ca54-4910-91f0-ea9da59ed3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ModelSaves/VGG16v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ModelSaves/VGG16v1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./ModelSaves/VGG16v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62222477-e4fe-45b4-8b86-9ec85663ce20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_model('./ModelSaves/VGG16v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd2ee14-6dce-40a9-94d7-731cc6ad3d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 131s 5s/step - loss: 2.4212 - accuracy: 0.6185\n",
      "Loss = 2.4211628437042236\n",
      "Test Accuracy = 0.6184689998626709\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, y_test_eye)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b319227f-ff8d-4a6f-bfb3-82305379cf21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ded2a0-2053-4921-992c-82c52b1adc21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08841e36-7962-43b2-a4be-9aa58111ab22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sum(np.argmax(preds, axis=1) == np.argmax(y_test_norm, axis=1)) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06eb541-8fe7-4712-8dd8-3413e274875b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(np.argmax(preds, axis=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191d36d-361b-43bd-9e86-e5448afae2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotions = [\"Happiness\", \"Sadness\", \"Fear\", \"Disgust\", \"Anger\", \"Surprise\"]\n",
    "\n",
    "emotion_presence = set()\n",
    "\n",
    "rands = []\n",
    "\n",
    "shuffle_indices = shuffle(range(len(preds)))\n",
    "\n",
    "for i in shuffle_indices:\n",
    "    if emotions[classes[i]] not in emotion_presence and np.argmax(preds[i]) == classes[i]:\n",
    "        rands.append(i)\n",
    "        emotion_presence.add(emotions[classes[i]])\n",
    "\n",
    "print(len(rands))\n",
    "\n",
    "while len(rands) < 5:\n",
    "    pos = random.randint(0, len(test_indices) - 1)\n",
    "    if emotions[classes[test_indices[pos]]] not in emotion_presence:\n",
    "        rands.append(pos)\n",
    "        emotion_presence.add(emotions[classes[test_indices[pos]]])\n",
    "\n",
    "# actuals = [test_indices[pos] for pos in rands]\n",
    "\n",
    "for i in range(len(actuals)):\n",
    "    print('========================================================')\n",
    "    print(book_links[actuals[i]])\n",
    "    display(Image.fromarray((X_test[rands[i]] * 255).astype(np.uint8)))\n",
    "    print(emotions[np.argmax(preds[i])])\n",
    "    im = Image.open(directory + str(actuals[i]) + \".jpg\")\n",
    "    im.thumbnail(dimensions, Image.ANTIALIAS)\n",
    "    display(im)\n",
    "    print(emotions[classes[actuals[i]]])\n",
    "    print('========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695e055-e21f-4771-bd47-29d7101268bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for i in range(len(y_test)):\n",
    "    real_class = y_test[i]\n",
    "    pred_class = np.argmax(preds[i])\n",
    "    if real_class in scores:\n",
    "        scores[real_class] = [scores[real_class][0] + int(real_class == pred_class), scores[real_class][1] + 1]\n",
    "    else:\n",
    "        scores[real_class] = [int(real_class == pred_class), 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7dc562-149c-43bf-a030-bd35788fb8fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in list(scores.keys()):\n",
    "    print(key, scores[key], scores[key][0] / scores[key][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401bb23-03c3-4ebc-9ffa-d643ae2f367f",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8814d9-fe26-454f-8a24-a8ada1a10cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8305, 200, 200, 3), (8305,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ros = RandomOverSampler()\n",
    "\n",
    "X_train_ros, y_train_ros = ros.fit_resample(\n",
    "    X_train.reshape((-1, X_train.shape[1] * X_train.shape[2] * X_train.shape[3])),\n",
    "    y_train\n",
    ")\n",
    "\n",
    "X_train_ros = X_train_ros.reshape((-1, X_train.shape[1], X_train.shape[2], X_train.shape[3]))\n",
    "X_train_ros.shape, y_train_ros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37326ced-fc48-423e-a2e6-9597055dd037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Necessary for ResNet Dense Layer\n",
    "y_train_ros_eye = np.eye(num_classes)[y_train_ros.reshape(-1)]\n",
    "y_test_eye = np.eye(num_classes)[y_test.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36b0aa5c-147f-4be6-83bd-6d50d7ce48c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "base_model = VGG16(weights= None, include_top=False, input_shape=(dimensions[0], dimensions[1], 3))\n",
    "# base_model = ResNet50(weights= None, include_top=False, input_shape=(dimensions[0], dimensions[1], 3))\n",
    "\n",
    "# Required for VGG16 in thi cae\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "# sgd = SGD(learning_rate=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08c2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "130/130 [==============================] - 5773s 44s/step - loss: 1.6095 - accuracy: 0.2190\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 5705s 44s/step - loss: 1.5987 - accuracy: 0.2226\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 5719s 44s/step - loss: 1.5221 - accuracy: 0.2848\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 5759s 44s/step - loss: 1.2613 - accuracy: 0.3966\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 5802s 45s/step - loss: 0.9182 - accuracy: 0.5440\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 53333s 413s/step - loss: 0.7470 - accuracy: 0.6033\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 5878s 45s/step - loss: 0.6820 - accuracy: 0.6148\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 5822s 45s/step - loss: 0.6874 - accuracy: 0.6194\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 5818s 45s/step - loss: 0.6486 - accuracy: 0.6466\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 5840s 45s/step - loss: 0.6820 - accuracy: 0.6426\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 5839s 45s/step - loss: 0.6237 - accuracy: 0.6772\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 5850s 45s/step - loss: 0.5295 - accuracy: 0.7318\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 42207s 327s/step - loss: 0.4523 - accuracy: 0.7750\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 5688s 44s/step - loss: 0.4011 - accuracy: 0.8014\n",
      "Epoch 15/50\n",
      " 88/130 [===================>..........] - ETA: 30:43 - loss: 0.3677 - accuracy: 0.8226"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_ros, y_train_ros_eye, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25361d-16ba-4ad7-8bea-e2ded70d030f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model.evaluate(X_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ba597-2606-4f18-9c92-011703a38adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('./ModelSaves/VGG16_oversampling_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe171a1-d487-4b18-9854-a26cb5b310ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 141s 5s/step - loss: 2.4212 - accuracy: 0.6185\n",
      "Loss = 2.4211628437042236\n",
      "Test Accuracy = 0.6184689998626709\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, y_test_eye)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e36c3e-0800-41bd-973b-84d6af9be169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9a84e-bf24-464e-b1b1-e67d640f65fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f0679-f5e6-43b1-9c7d-0e5fb5b055ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sum(np.argmax(preds, axis=1) == np.argmax(y_test_norm, axis=1)) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a79ba-63fd-44a6-91a0-bb4de242478b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(np.argmax(preds, axis=1), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7206098-4d8c-45d1-a201-54e6d231c58e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotions = [\"Happiness\", \"Sadness\", \"Fear\", \"Disgust\", \"Anger\", \"Surprise\"]\n",
    "\n",
    "emotion_presence = set()\n",
    "\n",
    "rands = []\n",
    "\n",
    "shuffle_indices = shuffle(range(len(preds)))\n",
    "\n",
    "for i in shuffle_indices:\n",
    "    if emotions[classes[i]] not in emotion_presence and np.argmax(preds[i]) == classes[i]:\n",
    "        rands.append(i)\n",
    "        emotion_presence.add(emotions[classes[i]])\n",
    "\n",
    "print(len(rands))\n",
    "\n",
    "while len(rands) < 5:\n",
    "    pos = random.randint(0, len(test_indices) - 1)\n",
    "    if emotions[classes[test_indices[pos]]] not in emotion_presence:\n",
    "        rands.append(pos)\n",
    "        emotion_presence.add(emotions[classes[test_indices[pos]]])\n",
    "\n",
    "# actuals = [test_indices[pos] for pos in rands]\n",
    "\n",
    "for i in range(len(actuals)):\n",
    "    print('========================================================')\n",
    "    print(book_links[actuals[i]])\n",
    "    display(Image.fromarray((X_test[rands[i]] * 255).astype(np.uint8)))\n",
    "    print(emotions[np.argmax(preds[i])])\n",
    "    im = Image.open(directory + str(actuals[i]) + \".jpg\")\n",
    "    im.thumbnail(dimensions, Image.ANTIALIAS)\n",
    "    display(im)\n",
    "    print(emotions[classes[actuals[i]]])\n",
    "    print('========================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b5075-7ee6-411a-9a64-8bf7c189a993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for i in range(len(y_test)):\n",
    "    real_class = y_test[i]\n",
    "    pred_class = np.argmax(preds[i])\n",
    "    if real_class in scores:\n",
    "        scores[real_class] = [scores[real_class][0] + int(real_class == pred_class), scores[real_class][1] + 1]\n",
    "    else:\n",
    "        scores[real_class] = [int(real_class == pred_class), 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bc9fd5-73d9-4a2b-b861-bb3a7d441246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in list(scores.keys()):\n",
    "    print(key, scores[key], scores[key][0] / scores[key][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e4b3ca-6316-4706-9d56-0bedd95dbb4b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
